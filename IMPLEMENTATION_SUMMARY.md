# Project Overview & Implementation Summary

## ğŸ¯ Project: Plagiarism Checker

A comprehensive, open-source plagiarism detection system with multi-user support, REST API, and advanced similarity algorithms.

---

## âœ¨ Implemented Features

### 1. âœ… Hybrid Similarity Detection
- **TF-IDF Algorithm**: Keyword-based similarity matching
- **Semantic Similarity**: AI-powered embedding-based matching using sentence-transformers
- **Combined Scoring**: Average of both methods for balanced results

**Files:**
- `utils/similarity.py` â€” Core similarity functions
- Uses `all-MiniLM-L6-v2` transformer model

### 2. âœ… Multi-user Dashboard (Streamlit)
- Username-based authentication (demo-friendly)
- User-specific document uploads and history
- Real-time plagiarism checking
- Download PDF reports and HTML diffs
- Report history with timestamps

**Files:**
- `app_streamlit.py` â€” Main dashboard application

### 3. âœ… REST API (Flask)
- User registration endpoint
- Document upload endpoint
- Plagiarism check endpoint
- Report retrieval endpoints
- File download endpoint

**Files:**
- `app_flask.py` â€” Flask API server
- See `API_REFERENCE.md` for full documentation

### 4. âœ… SQLite Database Integration
- Multi-table relational schema
- User management
- Document storage with extracted text
- Report tracking with scores and file paths
- SQLAlchemy ORM for easy queries

**Files:**
- `utils/db.py` â€” Database models and helpers

### 5. âœ… HTML Diff Reports
- Side-by-side comparison of texts
- Sentence-level highlighting
- Visual diff using Python's `difflib.HtmlDiff`
- Multiple matches combined in single HTML

**Files:**
- `utils/diff_report.py` â€” HTML diff generation

### 6. âœ… PDF Report Generation
- Professional PDF layout
- Similarity scores for all matches
- Reference to HTML diffs
- Multi-page support for large reports

**Files:**
- `utils/report.py` â€” PDF report generation

### 7. âœ… Document Processing
- PDF extraction (PyPDF2)
- DOCX extraction (python-docx)
- Text preprocessing and cleaning
- NLTK stopword filtering

**Files:**
- `utils/extractor.py` â€” Text extraction
- `utils/preprocessor.py` â€” Text cleaning

---

## ğŸ“ Project Structure

```
plagiarism-checker/
â”œâ”€â”€ README.md                    # Main documentation
â”œâ”€â”€ QUICKSTART.md               # 5-minute quick start
â”œâ”€â”€ INSTALLATION.md             # Detailed installation guide
â”œâ”€â”€ CONTRIBUTING.md             # Contribution guidelines
â”œâ”€â”€ API_REFERENCE.md            # API documentation
â”œâ”€â”€ SETUP_CHECKLIST.md          # Setup verification checklist
â”‚
â”œâ”€â”€ app_streamlit.py            # Multi-user Streamlit dashboard
â”œâ”€â”€ app_flask.py                # Flask REST API
â”œâ”€â”€ app.py                      # Legacy basic Streamlit app
â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ db.py                   # SQLite database models & helpers (NEW)
â”‚   â”œâ”€â”€ diff_report.py          # HTML diff generation (NEW)
â”‚   â”œâ”€â”€ extractor.py            # PDF/DOCX text extraction
â”‚   â”œâ”€â”€ preprocessor.py         # Text cleaning & tokenization
â”‚   â”œâ”€â”€ similarity.py           # TF-IDF & semantic similarity
â”‚   â””â”€â”€ report.py               # PDF report generation
â”‚
â”œâ”€â”€ corpus/                     # Reference documents (*.txt)
â”œâ”€â”€ uploads/                    # Temporary file storage
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ diffs/                  # Generated HTML diff files
â”‚
â””â”€â”€ plagiarism.db              # SQLite database (auto-created)
```

---

## ğŸš€ How to Get Started

### 1. Installation (5 minutes)

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or .\venv\Scripts\Activate.ps1 on Windows

# Install dependencies
pip install -r requirements.txt
```

### 2. Run the Application

**Option A: Streamlit Dashboard (Recommended)**
```bash
streamlit run app_streamlit.py
# Opens browser to http://localhost:8501
```

**Option B: Flask REST API**
```bash
python app_flask.py
# API available at http://localhost:5001
```

### 3. Try It Out

1. Login with any username
2. Upload a PDF or DOCX document
3. Click "Run Check"
4. View results and download reports

See `QUICKSTART.md` for more details!

---

## ğŸ“Š Database Schema

### Users Table
```sql
CREATE TABLE users (
    id INTEGER PRIMARY KEY,
    username STRING UNIQUE,
    created_at DATETIME
);
```

### Documents Table
```sql
CREATE TABLE documents (
    id INTEGER PRIMARY KEY,
    filename STRING,
    text TEXT,
    uploaded_by INTEGER,
    created_at DATETIME,
    FOREIGN KEY(uploaded_by) REFERENCES users(id)
);
```

### Reports Table
```sql
CREATE TABLE reports (
    id INTEGER PRIMARY KEY,
    user_id INTEGER,
    doc_id INTEGER,
    report_path STRING,
    diff_path STRING,
    overall_score FLOAT,
    created_at DATETIME,
    FOREIGN KEY(user_id) REFERENCES users(id),
    FOREIGN KEY(doc_id) REFERENCES documents(id)
);
```

---

## ğŸ”Œ API Endpoints

| Method | Endpoint | Purpose |
|--------|----------|---------|
| POST | `/register` | Create/retrieve user |
| POST | `/upload` | Upload document |
| POST | `/check` | Run plagiarism check |
| GET | `/reports/<user_id>` | Get user's reports |
| GET | `/download_report` | Download report file |

See `API_REFERENCE.md` for complete documentation with examples!

---

## âš™ï¸ Configuration & Tuning

### Similarity Thresholds
Edit `utils/similarity.py`:
```python
if s_score > 50.0:  # Adjust sensitivity
    if best_score > 40:  # Adjust match threshold
        matches.append((chunk, best, d["filename"]))
```

### Chunk Size
```python
def chunk_text(text, chunk_size=200):  # Adjust granularity
```

### Model Selection
```python
# In utils/similarity.py
model = SentenceTransformer('all-MiniLM-L6-v2')  # Change model here
```

### Database Location
```python
# In utils/db.py
DB_FILE = "plagiarism.db"  # Change path here
```

---

## ğŸ§ª Testing

### Manual Testing Checklist

- [ ] Streamlit app starts without errors
- [ ] Flask API responds to all endpoints
- [ ] Can upload PDF documents
- [ ] Can upload DOCX documents
- [ ] Plagiarism checks return valid scores
- [ ] PDF reports generate correctly
- [ ] HTML diffs display properly
- [ ] Database stores documents and reports
- [ ] Multi-user functionality works
- [ ] File downloads work

### Automated Testing (Optional)

Create `tests/` folder with test files:

```python
# tests/test_similarity.py
import pytest
from utils.similarity import tfidf_similarity, semantic_similarity

def test_identical_texts():
    text = "The quick brown fox"
    score = tfidf_similarity(text, text)
    assert score == 100.0
```

Run tests with:
```bash
pytest tests/
```

---

## ğŸ“š Documentation Files

| File | Purpose |
|------|---------|
| `README.md` | Complete project documentation |
| `QUICKSTART.md` | 5-minute getting started guide |
| `INSTALLATION.md` | Detailed setup instructions |
| `CONTRIBUTING.md` | Contribution guidelines |
| `API_REFERENCE.md` | REST API documentation |
| `SETUP_CHECKLIST.md` | Setup verification checklist |

---

## ğŸ¤ Contributing

The project welcomes contributions! See `CONTRIBUTING.md` for:
- Development workflow
- Coding standards
- Testing requirements
- Pull request process
- Feature ideas

Quick start for contributors:
```bash
git clone https://github.com/your-fork/plagiarism-checker.git
git checkout -b feature/my-feature
# Make changes
git commit -m "feat: description"
git push origin feature/my-feature
# Create pull request
```

---

## ğŸ”’ Security Considerations

âš ï¸ **Demo Mode**: Simple username authentication

**For Production**, implement:
- OAuth2 / OIDC authentication
- Password hashing (bcrypt)
- HTTPS/TLS encryption
- API key authentication
- Rate limiting
- Input validation
- File upload restrictions
- Database backups

See README.md for more security notes.

---

## ğŸ“ˆ Performance Characteristics

| Metric | Value |
|--------|-------|
| Typical check time | 5-30 seconds |
| Memory usage | ~1-2 GB during execution |
| Database file size | ~10-50 MB (with 100+ documents) |
| Model download size | ~500 MB |

### Optimization Tips
1. Reduce chunk size for faster processing
2. Adjust thresholds for fewer computations
3. Use lighter model: `distiluse-base-multilingual-cased-v2`
4. Cache embeddings in database (future enhancement)

---

## ğŸš€ Deployment Options

### Local Development
```bash
streamlit run app_streamlit.py
```

### Docker Containerization
```bash
docker build -t plagiarism-checker .
docker run -p 8501:8501 -p 5001:5001 plagiarism-checker
```

### Cloud Deployment
- Heroku: Include `Procfile` and `requirements.txt`
- AWS: Use EC2 + RDS + S3
- Google Cloud: App Engine or Cloud Run
- Azure: App Service + SQL Database

---

## ğŸ“ Future Enhancement Ideas

From the roadmap:

- [ ] Embedding caching for faster comparisons
- [ ] Web search integration (online plagiarism detection)
- [ ] Docker containerization
- [ ] Advanced analytics dashboard
- [ ] Batch processing API
- [ ] Mobile app (React Native)
- [ ] OAuth2 authentication
- [ ] Admin dashboard for corpus management
- [ ] Real-time collaboration features
- [ ] Citation detection
- [ ] Paraphrase detection
- [ ] Multi-language support

---

## ğŸ› Known Issues & Limitations

1. **First Run Time**: AI model downloads take 5-15 minutes
2. **Concurrent Users**: SQLite not ideal for heavy concurrent access (use PostgreSQL for production)
3. **Large Documents**: May be slow for PDFs > 50 pages
4. **Authentication**: Simple username-only (use proper auth for production)
5. **No Rate Limiting**: Add flask-limiter for production

---

## ğŸ“ Support & Troubleshooting

### Common Issues

**"Module not found"**
```bash
pip install -r requirements.txt
```

**"Port already in use"**
```bash
streamlit run app_streamlit.py --server.port 8502
```

**"Model download failed"**
- Check internet connection
- Wait 10-15 minutes
- Manually download model (see INSTALLATION.md)

### Getting Help

1. Check `README.md` troubleshooting section
2. Review `INSTALLATION.md`
3. Search GitHub issues
4. Open a new issue with error details

---

## ğŸ“„ License

This project is licensed under the **MIT License**.

---

## ğŸ‘ Acknowledgments

- **Sentence Transformers**: Semantic embeddings
- **Scikit-learn**: TF-IDF vectorization
- **Streamlit**: Web UI framework
- **Flask**: REST API framework
- **ReportLab**: PDF generation
- **SQLAlchemy**: Database ORM

---

## ğŸ“Š Project Statistics

- **Total Files**: 20+
- **Lines of Code**: ~2000+
- **Documentation Pages**: 6
- **API Endpoints**: 5
- **Database Tables**: 3
- **Supported File Formats**: PDF, DOCX

---

## ğŸ“ Learning Resources

This project demonstrates:
- Python application architecture
- Similarity algorithms (TF-IDF, semantic matching)
- Flask REST API design
- Streamlit dashboard development
- SQLAlchemy ORM usage
- Document processing
- PDF/HTML generation
- Multi-user application patterns

---

## ğŸ“¬ Questions or Feedback?

- Open an issue on GitHub
- Start a discussion
- Email maintainer
- Check documentation first!

---

**Enjoy using Plagiarism Checker! ğŸ‰**

*Implementation completed: November 2, 2025*
