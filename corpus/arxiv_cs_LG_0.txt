title hierarchical reinforcement learning maxq value function decomposition authors thomas g dietterich abstract paper presents maxq approach hierarchical reinforcement learning based decomposing target markov decision process mdp hierarchy smaller mdps decomposing value function target mdp additive combination value functions smaller mdps paper defines maxq hierarchy proves formal results representational power establishes five conditions safe use state abstractions paper presents online model free learning algorithm maxq q proves converges wih probability kind locally optimal policy known recursively optimal policy even presence five kinds state abstraction paper evaluates maxq representation maxq q series experiments three domains shows experimentally maxq q state abstractions converges recursively optimal policy much faster flat q learning fact maxq learns representation value function important benefit makes possible compute execute improved non hierarchical policy via procedure similar policy improvement step policy iteration paper demonstrates effectiveness non hierarchical execution experimentally finally paper concludes comparison related work discussion design tradeoffs hierarchical reinforcement learning