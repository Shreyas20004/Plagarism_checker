title truncating temporal differences efficient implementation td lambda reinforcement learning authors p cichosz abstract temporal difference td methods constitute class methods learning predictions multi step prediction problems parameterized recency factor lambda currently important application methods temporal credit assignment reinforcement learning well known reinforcement learning algorithms ahc q learning may viewed instances td learning paper examines issues efficient general implementation td lambda arbitrary lambda use reinforcement learning algorithms optimizing discounted sum rewards traditional approach based eligibility traces argued suffer inefficiency lack generality ttd truncated temporal differences procedure proposed alternative indeed approximates td lambda requires little computation per action used arbitrary function representation methods idea derived fairly simple new probably unexplored far encouraging experimental results presented suggesting using lambda gt ttd procedure allows one obtain significant learning speedup essentially cost usual td learning