title dynamic non bayesian decision making authors monderer tennenholtz abstract model non bayesian agent faces repeated game incomplete information nature appropriate tool modeling general agent environment interactions model environment state controlled nature may change arbitrarily feedback reward function initially unknown agent bayesian form prior probability neither state selection strategy nature reward function policy agent function assigns action every history observations actions two basic feedback structures considered one perfect monitoring case agent able observe previous environment state part feedback imperfect monitoring case available agent reward obtained settings refer partially observable processes current environment state unknown main result refers competitive ratio criterion perfect monitoring case prove existence efficient stochastic policy ensures competitive ratio obtained almost stages arbitrarily high probability efficiency measured terms rate convergence shown optimal policy exist imperfect monitoring case moreover proved perfect monitoring case exist deterministic policy satisfies long run optimality criterion addition discuss maxmin criterion prove deterministic efficient optimal strategy exist imperfect monitoring case criterion finally show approach long run optimality viewed qualitative distinguishes previous work area