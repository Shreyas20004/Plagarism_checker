title learning mixtures gaussians using k means algorithm authors kamalika chaudhuri sanjoy dasgupta andrea vattani abstract one popular algorithms clustering euclidean space k means algorithm k means difficult analyze mathematically theoretical guarantees known particularly data em well clustered paper attempt fill gap literature analyzing behavior k means well clustered data particular study case cluster distributed different gaussian words input comes mixture gaussians analyze three aspects k means algorithm assumption first show input comes mixture two spherical gaussians variant means algorithm successfully isolates subspace containing means mixture components second show exact expression convergence variant means algorithm input large number samples mixture spherical gaussians analysis require lower bound separation mixture components finally study sample requirement k means mixture spherical gaussians show upper bound number samples required variant means get close true solution sample requirement grows increasing dimensionality data decreasing separation means gaussians match upper bound show information theoretic lower bound algorithm learns mixtures two spherical gaussians lower bound indicates case overlap probability masses two distributions small sample requirement k means em near optimal