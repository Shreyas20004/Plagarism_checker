title regularizers structured sparsity authors charles micchelli jean morales massimiliano pontil abstract study problem learning sparse linear regression vector additional conditions structure sparsity pattern problem relevant machine learning statistics signal processing well known linear regression benefit knowledge underlying regression vector sparse combinatorial problem selecting nonzero components vector relaxed regularizing squared error convex penalty function like ell norm however many applications additional conditions structure regression vector sparsity pattern available incorporating information learning method may lead significant decrease estimation error paper present family convex penalty functions encode prior knowledge structure vector formed absolute values regression coefficients family subsumes ell norm flexible enough include different models sparsity patterns practical theoretical importance establish basic properties penalty functions discuss examples computed explicitly moreover present convergent optimization algorithm solving regularized least squares penalty functions numerical simulations highlight benefit structured sparsity advantage offered approach lasso method related methods