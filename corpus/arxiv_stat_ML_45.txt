title forest garrote authors nicolai meinshausen abstract variable selection high dimensional linear models received lot attention lately mostly context l regularization part attraction variable selection effect parsimonious models obtained suitable interpretation terms predictive power however regularized linear models often slightly inferior machine learning procedures like tree ensembles tree ensembles hand lack usually formal way variable selection difficult visualize garrote style convex penalty trees ensembles particular random forests proposed penalty selects functional groups nodes trees could simple monotone functions individual predictor variables yields parsimonious function fit lends easily visualization interpretation predictive power maintained least level original tree ensemble key feature method tree ensemble fitted tuning parameter needs selected empirical performance demonstrated wide array datasets