title line regression competitive reproducing kernel hilbert spaces authors vladimir vovk abstract consider problem line prediction real valued labels assumed bounded absolute value known constant new objects known labeled objects prediction algorithm performance measured squared deviation predictions actual labels stochastic assumptions made way labels objects generated instead given benchmark class prediction rules hoped produce good predictions show wide range infinite dimensional benchmark classes one construct prediction algorithm whose cumulative loss first n examples exceed cumulative loss prediction rule class plus sqrt n main differences known results impose upper bound norm considered prediction rules achieve optimal leading term excess loss algorithm benchmark class universal dense class continuous functions compact set provides line non stochastic analogue universally consistent prediction non parametric statistics use two proof techniques one based aggregating algorithm recently developed method defensive forecasting