title linearly parameterized bandits authors paat rusmevichientong john n tsitsiklis abstract consider bandit problems involving large possibly infinite collection arms expected reward arm linear function r dimensional random vector mathbf z mathbb r r r geq objective minimize cumulative regret bayes risk set arms corresponds unit sphere prove regret bayes risk order theta r sqrt establishing lower bound arbitrary policy showing matching upper bound obtained policy alternates exploration exploitation phases phase based policy also shown effective set arms satisfies strong convexity condition case general set arms describe near optimal policy whose regret bayes risk admit upper bounds form r sqrt log