title inferring dynamic bayesian networks using frequent episode mining authors debprakash patnaik srivatsan laxman naren ramakrishnan abstract motivation several different threads research proposed modeling mining temporal data one hand approaches dynamic bayesian networks dbns provide formal probabilistic basis model relationships time indexed random variables models intractable learn general case algorithms frequent episode mining scalable large datasets exhibit rigorous probabilistic interpretations mainstay graphical models literature results present unification two seemingly diverse threads research demonstrating dynamic discrete bayesian networks inferred results frequent episode mining helps bridge modeling emphasis former counting emphasis latter first show reasonable assumptions data characteristics influences random variables optimal dbn structure computed using greedy local algorithm next connect optimality dbn structure notion fixed delay episodes counts distinct occurrences finally demonstrate practical feasibility approach focus specific broadly applicable class networks called excitatory networks show search optimal dbn structure conducted using information frequent episodes application datasets gathered mathematical models spiking neurons well real neuroscience datasets presented availability algorithmic implementations simulator codebases datasets available website http neural code cs vt edu dbn