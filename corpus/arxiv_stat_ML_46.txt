title feature importance ranking measure authors alexander zien nicole kraemer soeren sonnenburg gunnar raetsch abstract accurate predictions typically obtained learning machines complex feature spaces e g induced kernels unfortunately decision rules hardly accessible humans cannot easily used gain insights application domain therefore one often resorts linear models combination variable selection thereby sacrificing predictive power presumptive interpretability introduce feature importance ranking measure firm retrospective analysis arbitrary learning machines allows achieve excellent predictive performance superior interpretation contrast standard raw feature weighting firm takes underlying correlation structure features account thereby able discover relevant features even appearance training data entirely prevented noise desirable properties firm investigated analytically illustrated simulations