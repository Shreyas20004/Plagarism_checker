title fast convergence rate multiple kernel learning elastic net regularization authors taiji suzuki ryota tomioka masashi sugiyama abstract investigate learning rate multiple kernel leaning mkl elastic net regularization consists ell regularizer inducing sparsity ell regularizer controlling smoothness focus sparse setting total number kernels large number non zero components ground truth relatively small prove elastic net mkl achieves minimax learning rate ell mixed norm ball bound sharper convergence rates ever shown property smoother truth faster convergence rate