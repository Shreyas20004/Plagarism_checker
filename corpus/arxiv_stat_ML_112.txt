title bagging svm learn positive unlabeled examples authors fantine mordelet jean philippe vert abstract consider problem learning binary classifier training set positive unlabeled examples inductive transductive setting problem often referred emph pu learning differs standard supervised classification problem lack negative examples training set corresponds ubiquitous situation many applications information retrieval gene ranking identified set data interest sharing particular property wish automatically retrieve additional data sharing property among large easily available pool unlabeled data propose conceptually simple method akin bagging approach inductive transductive pu learning problems converting series supervised binary classification problems discriminating known positive examples random subsamples unlabeled set empirically demonstrate relevance method simulated real data performs least well existing methods faster