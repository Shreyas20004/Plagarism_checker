title estimation stochastic attribute value grammars using informative sample authors miles osborne abstract argue computational complexity associated estimation stochastic attribute value grammars reduced training upon informative subset full training set results using parsed wall street journal corpus show circumstances possible obtain better estimation results using informative sample training upon available material experimentation demonstrates unlexicalised models gaussian prior reduce overfitting however models lexicalised contain overlapping features overfitting seem problem gaussian prior makes minimal difference performance approach applicable situations infeasibly large number parses training set else recovery parses packed representation computationally expensive